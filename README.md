# Data Processing Project

This repository contains a robust data processing pipeline designed to extract, transform, and load data from an Excel spreadsheet, validate it, and publish the results as a JSON file. The entire workflow is automated using GitHub Actions for continuous integration and deployment.

## Project Structure

- `data.xlsx`: The original Excel file containing the raw input data.
- `data.csv`: A CSV representation of `data.xlsx`, generated as an intermediate step for potential easier processing or compatibility.
- `execute.py`: A Python script responsible for reading, cleaning, and transforming the data from `data.xlsx`.
- `.github/workflows/ci.yml`: The GitHub Actions workflow definition for linting, executing the script, and deploying the results.
- `result.json`: The final processed data in JSON format, generated by `execute.py` and published via GitHub Pages (not committed to the repository).
- `index.html`: A single-file responsive HTML page providing an overview of the project.
- `LICENSE`: The MIT License text for the project.

## `execute.py` - Python Data Processor

The `execute.py` script is written in Python 3.11+ and leverages the Pandas 2.3 library for efficient data manipulation. Its primary functions include:

1.  **Reading Data**: Reads the `data.xlsx` file.
2.  **Data Cleaning & Type Coercion**: A non-trivial error related to data types in the input Excel file has been identified and fixed. Specifically, the script now robustly handles columns that might contain non-numeric data when a numeric operation is expected. It uses `pd.to_numeric(..., errors='coerce')` to convert relevant columns to numeric types, turning any unparseable values into `NaN`, and then handles these `NaN` values (e.g., by dropping rows or filling with a default). This ensures that mathematical operations proceed without errors.
3.  **Data Transformation**: Performs aggregations (e.g., grouping by a category and summing values) to produce a summarized output.
4.  **JSON Output**: Outputs the final processed data as a compact JSON string to standard output, which is then redirected to `result.json` in the CI pipeline.

**Requirements:**
- Python 3.11+
- pandas==2.3.x
- openpyxl (for reading .xlsx files)

## `data.csv` - Converted Data

`data.csv` is a direct CSV conversion of `data.xlsx`. This file is generated as part of the initial data setup and committed to the repository. It provides a plain-text version of the dataset, which can be useful for quick inspection or alternative processing.

## GitHub Actions Workflow (`.github/workflows/ci.yml`)

The CI/CD pipeline is configured to run on every push to the `main` branch, or manually via `workflow_dispatch`. It performs the following steps:

1.  **Checkout Code**: Retrieves the repository content.
2.  **Setup Python**: Configures a Python 3.11 environment and caches pip dependencies.
3.  **Install Dependencies**: Installs `pandas`, `ruff`, and `openpyxl`.
4.  **Run Ruff Linter**: Executes `ruff check .` to ensure code quality and adherence to style guidelines. Results are shown directly in the CI log.
5.  **Execute Script & Generate `result.json`**: Runs `python execute.py > result.json`. The output JSON file is generated dynamically during this step.
6.  **Setup GitHub Pages**: Configures the environment for deploying to GitHub Pages.
7.  **Upload Pages Artifact**: Uploads `result.json` as an artifact to be served by GitHub Pages.
8.  **Deploy to GitHub Pages**: Deploys the uploaded artifact to the project's GitHub Pages site, making `result.json` publicly accessible.

**Note:** `result.json` is *not* committed to the repository; it is generated and published solely by the CI pipeline.

## Getting Started Locally

1.  **Clone the repository:**
    ```bash
    git clone [your-repo-url]
    cd [your-repo-name]
    ```
2.  **Install dependencies:**
    ```bash
    pip install pandas openpyxl ruff
    ```
3.  **Run the script:**
    ```bash
    python execute.py > result.json
    ```
4.  **Lint with Ruff:**
    ```bash
    ruff check .
    ```

## License

This project is licensed under the MIT License - see the `LICENSE` file for details.
